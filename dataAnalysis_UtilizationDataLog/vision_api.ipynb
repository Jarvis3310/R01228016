{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.5.2 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "cv2 version: 3.3.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darkflow.net.build import TFNet\n",
    "print('python version:', sys.version)\n",
    "print('cv2 version:', cv2.__version__)\n",
    "## tensorflow-gpu \n",
    "## CUDA 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ckeck tensorflow gpu\n",
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "# ---\n",
    "# What returns in cmd\n",
    "# reference: https://stackoverflow.com/questions/38009682/how-to-tell-if-tensorflow-is-using-gpu-acceleration-from-inside-python-shell\n",
    "# 2017-11-02 23:23:21.039622: I tensorflow/core/common_runtime/direct_session.cc:300] Device mapping:\n",
    "# /job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce 920M, pci bus id: 0000:04:00.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Frame_caculator Func\n",
    "This is just for test. Cause it will play in real-time-counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### This is just for test( Could do by mutiple fps with video_lengthSeconds)\n",
    "# def frame_caculator(video_path):\n",
    "#     total_frame = 0\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     while(True):\n",
    "#         try:\n",
    "#             ret, frame = cap.read()\n",
    "#             # cv2.imshow('frame',frame)\n",
    "#             if ret:\n",
    "#                 total_frame +=1\n",
    "#                 # Quit\n",
    "#                 if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                     break\n",
    "#             else:\n",
    "#                 break\n",
    "#         except:\n",
    "#             break\n",
    "#     print('this is end', total_frame)\n",
    "#     # When everything done, release the capture\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# Example frame_caculator\n",
    "# frame_caculator('./test.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Cut Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def video_cut(video_path, video_timeLength, video_fps, startTime_second, endTime_second, \n",
    "              output_fps, output_w, output_h, output_name='output.avi'):\n",
    "    \"\"\"\n",
    "        1. Input: video_path\n",
    "        2. Input: video_timeLength, the [total length of video] in seconds.\n",
    "        3. Input: video_fps, the [frames per second].\n",
    "        4. Input: startTime_second, is the [percentage of the spliting_start_time] of the video.\n",
    "        5. Input: endTime_second, is the [percentage of the spliting_end_time] of the video. \n",
    "        6. Input: set toe output video's [Output_fps, output_w, output_h].\n",
    "        7. Output: will be [.avi] format video with the [split part] of video.\n",
    "    \"\"\"\n",
    "    # Capture video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_name, fourcc, output_fps, (output_w, output_h))\n",
    "    \n",
    "    # Set specific frame-range of video\n",
    "    frame_total = video_timeLength * video_fps   # 0 - frame_total\n",
    "    frame_start = startTime_second * video_fps   \n",
    "    frame_end = endTime_second * video_fps\n",
    "    print(frame_start, '--->', frame_end)\n",
    "    \n",
    "    # Check time \n",
    "    e1 = cv2.getTickCount()\n",
    "    \n",
    "    for i in range(frame_start, frame_end):\n",
    "        \n",
    "        # Set frame selection with frame place-percent(between 0.0-1.0)\n",
    "        cap.set(1, i)\n",
    "        \n",
    "        # Read and Save\n",
    "        ret, frame = cap.read()\n",
    "        print(i)\n",
    "        if ret:\n",
    "            \n",
    "            # Some tricks\n",
    "            kernel = np.ones((3,3),np.uint8)\n",
    "            frame = cv2.morphologyEx(frame, cv2.MORPH_OPEN, kernel)\n",
    "            \n",
    "            # Resize it \n",
    "            frame = cv2.resize(frame,(output_w, output_h), interpolation = cv2.INTER_CUBIC)\n",
    "            \n",
    "            # write the frame to the output\n",
    "            out.write(frame)\n",
    "            \n",
    "            # Show \n",
    "            cv2.imshow('frame',frame)\n",
    "            \n",
    "            # Exit\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    # Check time spent\n",
    "    e2 = cv2.getTickCount()\n",
    "    print('Cost time:',(e2 - e1)/cv2.getTickFrequency())\n",
    "    \n",
    "    # Release everything if job is finished\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Video_cut Example \n",
    "# video_cut(video_path='./MrSmith.mp4',   # path to access video  \n",
    "#           video_timeLength=(5*60+8),    # Input video's property: total time-Length in second. \n",
    "#           video_fps=30,                 # Input video's property: video's frame per second.\n",
    "#           startTime_second=(0*60+22),   # cut_start_second:  ex: 20\n",
    "#           endTime_second=(0*60+40),     # cut_end_second:    ex: 30\n",
    "#           output_fps=30,                # Output video's property: video's frame per second. \n",
    "#           output_h=800,                 # Output video's property: video's height.\n",
    "#           output_w=600,                 # Output video's property: video's width. \n",
    "#           output_name='smith_18.avi')      # Output video's property: video's name. (format can't be changed here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def videos_merge(video_path_list, output_fps, output_w, output_h, output_name = 'mergeee.avi'):\n",
    "    \"\"\"\n",
    "        1. Input: video_path_list\n",
    "        2. Input: set toe output video's [Output_fps, output_w, output_h].\n",
    "        3. Output: will be [.avi] format [merged] video.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_name, fourcc, output_fps, (output_w, output_h))\n",
    "\n",
    "    # Check time spent\n",
    "    e1 = cv2.getTickCount()\n",
    "    for video in video_path_list:\n",
    "        print('Start:', video)\n",
    "        \n",
    "        # Capture video\n",
    "        cap = cv2.VideoCapture(video)\n",
    "        while(True):\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read() \n",
    "            if ret:\n",
    "                # write the frame to the output\n",
    "                out.write(frame)\n",
    "\n",
    "                # Show \n",
    "                cv2.imshow('frame',frame)\n",
    "\n",
    "                # Exit\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break \n",
    "        print('End:', video)\n",
    "        \n",
    "    # Check time spent\n",
    "    e2 = cv2.getTickCount()\n",
    "    print('Cost time:',(e2 - e1)/cv2.getTickFrequency())\n",
    "    \n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # videos_merge Example\n",
    "# video_path_list = ['./catdog_18.avi', './smith_18.avi', './conan_18.avi', './keny_181.avi', './keny_182.avi']\n",
    "# videos_merge(video_path_list=video_path_list, output_fps=30, output_h=800, output_w=600, output_name='mergeee.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def video_format_transfer(video_path, output_format='mp4', output_name='video_formatted', output_fps=30, output_w=800, output_h=600):\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    if output_format == 'mp4':\n",
    "        fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "    elif output_format == 'avi':\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    else:\n",
    "        fourcc = 0\n",
    "    \n",
    "    if fourcc:\n",
    "        out = cv2.VideoWriter(output_name, fourcc, output_fps, (output_w, output_h))\n",
    "\n",
    "        # Check time spent\n",
    "        e1 = cv2.getTickCount()\n",
    "        # Capture video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        while(True):\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read() \n",
    "            if ret:\n",
    "                # Resize it \n",
    "                frame = cv2.resize(frame,(output_w, output_h), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "                # write the frame to the output\n",
    "                out.write(frame)\n",
    "\n",
    "                # Show \n",
    "                cv2.imshow('frame',frame)\n",
    "\n",
    "                # Exit\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break \n",
    "\n",
    "        # Check time spent\n",
    "        e2 = cv2.getTickCount()\n",
    "        print('End:', video_path)\n",
    "        print('Cost time:',(e2 - e1)/cv2.getTickFrequency())\n",
    "\n",
    "        # When everything done, release the capture\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()       \n",
    "    else:\n",
    "        print('please Input the correct format: [\"MP4\" or \"AVI\"] ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# video_format_transfer Example :\n",
    "video_format_transfer('./test.mpg', output_format='avi', output_name='video_formatted.mp4', output_fps=30, output_w=800, output_h=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow with gpu then [ \"gpu\": 0.7 will be working. ]\n",
    "# Reference: https://www.google.com.tw/search?q=darkflow+gpu&oq=darkflow+gpu&aqs=chrome..69i57.3855j0j7&sourceid=chrome&ie=UTF-8\n",
    "\n",
    "# >>> conda unistall tensorflow: 1.3.0-py35_0 conda-forge\n",
    "# >>> conda install tensorflow-gpu or pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CUDA with opencv? \n",
    "# https://jamesbowley.co.uk/buildcompile-opencv-v3-3-on-windows-with-cuda-8-0-and-intel-mkltbb/ 看不懂！？\n",
    "# https://www.scivision.co/anaconda-python-opencv3/ \n",
    "\n",
    "# print(cv2.getBuildInformation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conda config --add channels conda-forge\n",
    "# conda install --use-local opencv\n",
    "# sudo apt-get install libavcodec-dev libavformat-dev libavdevice-dev\n",
    "# sudo apt-get install pkg-config\n",
    "# sudo apt-get install libgtk2.0-dev\n",
    "\n",
    "\n",
    "\n",
    "# problem issue # opencv Unable to stop the stream: Inappropriate ioctl for device\n",
    "# https://stackoverflow.com/questions/42562876/opencv3-error-unable-to-stop-the-stream-inappropriate-ioctl-for-device\n",
    "# https://stackoverflow.com/questions/41200201/opencv-unable-to-stop-the-stream-inappropriate-ioctl-for-device\n",
    "\n",
    "\n",
    "# OR JUST INSTALL cv2 version: 3.3.0\n",
    "# 3.3 problem # scn == 3 || scn == 4 in function cvtColor\n",
    "# https://github.com/HackerHouseYT/AI-Smart-Mirror/issues/36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFNet Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Object Detection with Darkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VOD_darkflow(video_path, video_fps, video_h, video_w, tf_threshold=0.3, tf_gpu=0.9, output_name='VOD_result.avi'):\n",
    "    \n",
    "    # Set TFNet initiail options\n",
    "    options = {\"model\": \"cfg/yolo.cfg\",\n",
    "               \"load\": \"bin/yolo.weights\",\n",
    "               \"threshold\": tf_threshold,\n",
    "               \"gpu\": tf_gpu}    \n",
    "    tfnet = TFNet(options)\n",
    "    \n",
    "    # Capture Video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_name, fourcc, video_fps, (video_h, video_w))\n",
    "    \n",
    "    # Record use\n",
    "    total_time = 0            # Caculate total time-cost\n",
    "    tag_list = []             # Store detected object tags\n",
    "    itemImage_list = []       # Store detected images\n",
    "    i = 0                     # Skip frame use \n",
    "    \n",
    "    while(True):\n",
    "        \n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check time \n",
    "        e1 = cv2.getTickCount()\n",
    "\n",
    "#         if ret & ((i%5) == 0):\n",
    "        if ret:\n",
    "            # Prediction with darkflow\n",
    "            print('=== Start Predicting with darkflow ===')\n",
    "            predictions = tfnet.return_predict(frame)\n",
    "            for x in range(len(predictions)):\n",
    "                            if predictions!=[]:\n",
    "                                topleftx = predictions[x]['topleft']['x']\n",
    "                                toplefty = predictions[x]['topleft']['y']\n",
    "                                bottomrightx = predictions[x]['bottomright']['x']\n",
    "                                bottomrighty = predictions[x]['bottomright']['y']\n",
    "                                detect = predictions[x]['label']\n",
    "                                print(predictions[x]['confidence'])\n",
    "                                if detect not in tag_list:\n",
    "                                    tag_list.append(detect)\n",
    "                                    detected_obj = frame[toplefty:bottomrighty, topleftx:bottomrightx] #[height1:height2, width1:width2]\n",
    "                                    if predictions[x]['confidence'] >= 0.7:\n",
    "                                        cv2.imwrite('./objImg_high/{0}.png'.format(detect),detected_obj)\n",
    "                                    elif predictions[x]['confidence'] >= 0.4:\n",
    "                                        cv2.imwrite('./objImg_mid/{0}.png'.format(detect),detected_obj)\n",
    "                                    else:\n",
    "                                        cv2.imwrite('./objImg_low/{0}.png'.format(detect),detected_obj)\n",
    "                                confidence = str(predictions[x]['confidence'])\n",
    "                                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                                cv2.rectangle(frame,(topleftx,toplefty),(bottomrightx,bottomrighty),(0,255,0),3)\n",
    "                                cv2.putText(frame,detect,(bottomrightx-150,bottomrighty-60), font, 2,(0,0,255),2,cv2.LINE_AA)\n",
    "                                cv2.putText(frame,confidence,(bottomrightx-150,bottomrighty-20), font, 1,(80,50,255),2,cv2.LINE_AA)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame',frame)\n",
    "\n",
    "        # write the frame to the output\n",
    "#         out.write(frame)\n",
    "\n",
    "        # Check time spent\n",
    "        e2 = cv2.getTickCount()\n",
    "        print('Cost time:',(e2 - e1)/cv2.getTickFrequency())\n",
    "        total_time += ((e2 - e1)/cv2.getTickFrequency())\n",
    "        \n",
    "        # Skip frame \n",
    "        i += 1\n",
    "\n",
    "        # Quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Print Finished Hint Message\n",
    "    print(\"=== VOD_darkflow has finished. ===\")\n",
    "    print(\"Video was saved as:\", output_name)\n",
    "    \n",
    "    # Print Total Time Spent\n",
    "    print(\"=== Total Time Spent ===\")\n",
    "    print(total_time)\n",
    "            \n",
    "    # Print Tag List\n",
    "    print(\"=== Object Detected ===\")\n",
    "    print(tag_list)\n",
    "    \n",
    "    \n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# VOD_darkflow Example:\n",
    "VOD_darkflow(video_path=0, \n",
    "             video_fps=30, \n",
    "             video_h=800, \n",
    "             video_w=600, \n",
    "             output_name='test.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./cfg/yolo.cfg\n",
      "Parsing cfg/yolo.cfg\n",
      "Loading bin/yolo.weights ...\n",
      "Successfully identified 269862452 bytes\n",
      "Finished in 0.131866455078125s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 416, 416, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 26, 26, 512)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 13, 13, 2048)\n",
      " Load  |  Yep!  | concat [26, 24]                  | (?, 13, 13, 3072)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "GPU mode with 0.9 usage\n",
      "Finished in 5.588002443313599s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set TFNet (i%500) == 0initiail options\n",
    "options = {\"model\": \"cfg/yolo.cfg\",\n",
    "           \"load\": \"bin/yolo.weights\",\n",
    "           \"threshold\": 0.3,\n",
    "           \"gpu\": 0.9}\n",
    "\n",
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': ['6'], 'b': 6}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'a' in list(t_dic.keys())\n",
    "t_dic['a'] = []\n",
    "t_dic['a'].append('6')\n",
    "t_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 8.38959978\n",
      "Cost time: 6.64e-06\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.567260936\n",
      "Cost time: 5.008e-06\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.562244104\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.546485416\n",
      "Cost time: 5.861e-06\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.581933836\n",
      "Cost time: 5.299e-06\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.524800843\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.566404281\n",
      "Cost time: 4.881e-06\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.565133061\n",
      "Cost time: 3.754e-06\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.592110048\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.633092236\n",
      "Cost time: 6.226e-06\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.564038886\n",
      "Cost time: 5.601e-06\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.571781619\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.604738716\n",
      "Cost time: 9.643e-06\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.597792635\n",
      "Cost time: 6.115e-06\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.636400309\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.616119985\n",
      "Cost time: 6.13e-06\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.55851367\n",
      "Cost time: 5.27e-06\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.592437992\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.591522568\n",
      "Cost time: 4.332e-06\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.528047388\n",
      "Cost time: 4.284e-06\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.58692831\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.538711624\n",
      "Cost time: 4.766e-06\n",
      "=== Start Predicting with darkflow ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cd0f4cdc6161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Prediction with tfnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'=== Start Predicting with darkflow ==='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pikajiyu/Downloads/darkflow-master/darkflow/net/flow.py\u001b[0m in \u001b[0;36mreturn_predict\u001b[0;34m(self, im)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minp\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mthis_inp\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pikajiyu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pikajiyu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pikajiyu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pikajiyu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pikajiyu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    "\n",
    "# CAM\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Demo Video\n",
    "cap = cv2.VideoCapture('./mergeee.avi')\n",
    "\n",
    "# # Define the codec and create VideoWriter object\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# out = cv2.VideoWriter(output_name, fourcc, output_fps, (output_h, output_w))\n",
    "\n",
    "total_time = 0            # Caculate total time-cost\n",
    "total_tag_list = []       # Store detected object tags\n",
    "total_info = {}\n",
    "high_tag_dict = {}\n",
    "mid_tag_dict = {}\n",
    "low_tag_dict = {}\n",
    "i = 0                     # Skip frame use \n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check time \n",
    "    e1 = cv2.getTickCount()\n",
    "\n",
    "    if ret & (i%5) == 0:\n",
    "        # Initial dict for each frame\n",
    "        total_info[i] = []\n",
    "        \n",
    "        # Prediction with tfnet \n",
    "        print('=== Start Predicting with darkflow ===')\n",
    "        predictions = tfnet.return_predict(frame)\n",
    "        if predictions:\n",
    "            for item in predictions:\n",
    "                # Prediction information \n",
    "                top_left_x = item['topleft']['x']\n",
    "                top_left_y = item['topleft']['y']\n",
    "                bot_right_x = item['bottomright']['x']\n",
    "                bot_right_y = item['bottomright']['y']\n",
    "                label = item['label']\n",
    "                confidence = item['confidence']\n",
    "                \n",
    "                # Create rectangle for detected object\n",
    "                cv2.rectangle(frame, (top_left_x, top_left_y), (bot_right_x, bot_right_y), (0,255,0), 3)\n",
    "                cv2.putText(frame, label, (bot_right_x-150, bot_right_y-60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(frame, str(round(confidence, 3)),(bot_right_x-150,bot_right_y-20), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1,(80,50,255),2,cv2.LINE_AA)\n",
    "\n",
    "                # Detected object image \n",
    "                detected_obj = frame[top_left_y:bot_right_y, top_left_x:bot_right_x] #[height1:height2, width1:width2]\n",
    "                \n",
    "                # Store information and images\n",
    "                if label not in total_tag_list:\n",
    "                    total_tag_list.append(label)\n",
    "                \n",
    "                total_info[i].append((label, str(round(confidence, 3))))\n",
    "                                     \n",
    "                if confidence > 0.7:\n",
    "                    if label not in list(high_tag_dict.keys()):\n",
    "                        high_tag_dict[label] = (str(round(confidence, 2))+'_'+str(i))\n",
    "                        if not os.path.exists('./objImg_high'):\n",
    "                            os.makedirs('./objImg_high')\n",
    "                        cv2.imwrite('./objImg_high/{0}_{1}.png'.format(label, (str(round(confidence, 2))+'_'+str(i))), detected_obj)\n",
    "                            \n",
    "                elif confidence > 0.4:\n",
    "                    if label not in list(mid_tag_dict.keys()):\n",
    "                        mid_tag_dict[label] = (str(round(confidence, 2))+'_'+str(i))\n",
    "                        if not os.path.exists('./objImg_mid'):\n",
    "                            os.makedirs('./objImg_mid')\n",
    "                        cv2.imwrite('./objImg_mid/{0}_{1}.png'.format(label, (str(round(confidence, 2))+'_'+str(i))), detected_obj)\n",
    " \n",
    "                else:\n",
    "                    if label not in list(low_tag_dict.keys()):\n",
    "                        low_tag_dict[label] = (str(round(confidence, 2))+'_'+str(i))\n",
    "                        if not os.path.exists('./objImg_low'):\n",
    "                            os.makedirs('./objImg_low')\n",
    "                        cv2.imwrite('./objImg_low/{0}_{1}.png'.format(label, (str(round(confidence, 2))+'_'+str(i))), detected_obj)\n",
    "        \n",
    "    # Display the resulting frame\n",
    "#     cv2.imshow('frame',frame)\n",
    "    \n",
    "    # write the frame to the output\n",
    "#     out.write(frame)\n",
    "    \n",
    "    # Check time spent\n",
    "    e2 = cv2.getTickCount()\n",
    "    print('Cost time:',(e2 - e1)/cv2.getTickFrequency())\n",
    "    \n",
    "    # Skip frame \n",
    "    i += 1\n",
    "    \n",
    "    # Quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Print Tag List\n",
    "print(\"=== Object Detected ===\")\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total_tag_list\n",
    "# total_info\n",
    "# high_tag_dict\n",
    "# mid_tag_dict\n",
    "# low_tag_dict\n",
    "# low_tag_dict.items()\n",
    "# low_tag_dict.keys()\n",
    "# pd.DataFrame(low_tag_dict.items(), columns=[low_tag_dict.keys])\n",
    "# pd.DataFrame(d.items(), columns=['Date', 'DateValue'])\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "import json\n",
    "\n",
    "def to_json(dicto, json_file_name='test.json'):\n",
    "    js = json.dumps(dicto)\n",
    "    # Open new json file if not exist it will create\n",
    "    fp = open('test.json', 'a')\n",
    "    # write to json file\n",
    "    fp.write(js)\n",
    "    # close the connection\n",
    "    fp.close()\n",
    "    \n",
    "to_json(dicto=low_tag_dict, json_file_name='low_tag_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.5.2 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "cv2 version: 3.3.0\n",
      "Parsing ./cfg/yolo.cfg\n",
      "Parsing cfg/yolo.cfg\n",
      "Loading bin/yolo.weights ...\n",
      "Successfully identified 269862452 bytes\n",
      "Finished in 0.07049036026000977s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 416, 416, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 26, 26, 512)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 13, 13, 2048)\n",
      " Load  |  Yep!  | concat [26, 24]                  | (?, 13, 13, 3072)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "GPU mode with 0.9 usage\n",
      "Finished in 17.315481901168823s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darkflow.net.build import TFNet\n",
    "print('python version:', sys.version)\n",
    "print('cv2 version:', cv2.__version__)\n",
    "## tensorflow-gpu \n",
    "## CUDA 7.5\n",
    "\n",
    "options = {\"model\": \"cfg/yolo.cfg\",\n",
    "           \"load\": \"bin/yolo.weights\",\n",
    "           \"threshold\": 0.3,\n",
    "           \"gpu\": 0.9}\n",
    "\n",
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
